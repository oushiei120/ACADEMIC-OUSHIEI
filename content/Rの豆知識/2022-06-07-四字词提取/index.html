---
title: 四字词-检索
author: Package Build
date: '2022-06-07'
slug: ''
categories: []
tags: []
lastmod: ~
description: ~
enableDisqus: no
enableMathJax: no
toc: no
---



<div id="load-package" class="section level2">
<h2>1.load package</h2>
<pre class="r"><code>suppressPackageStartupMessages({
  require(quanteda)
  library(tidytext)
  library(devtools)
  library(jiebaR)
  library(readtext)
  library(tidyverse)
  library(tidyr)
})</code></pre>
</div>
<div id="convert-and-load-a-user-dictionary-for-jiebar" class="section level2">
<h2>2.convert and load a user dictionary for jiebaR</h2>
<p>but actually the dictionary file which we download from sogou is not the file type jiebaR can recognize.So the cidian package is very helpful</p>
<pre class="r"><code>##convert the scel to the &quot;.dic&quot; file
##library(cidian)
decode_scel(scel = &quot;/Users/oushiei/Downloads/【源文件】成语俗语.scel&quot;)</code></pre>
</div>
<div id="set-a-worker-sgementuseris-essential" class="section level2">
<h2>3.Set a worker sgement,“user=”is essential</h2>
<pre class="r"><code>my_seg &lt;- worker(bylines=T,symbol = T,user = &quot;/Users/oushiei/Downloads/四字词文件/【源文件】成语俗语.dict&quot;)##四字词</code></pre>
</div>
<div id="read-the-file-use-readtext-function-and-sgement" class="section level2">
<h2>4. read the file use readtext function and sgement</h2>
<pre class="r"><code>r1 &lt;- readtext(&quot;/Users/oushiei/Downloads/细雪两译本对比分析代码-文档合集/细雪txt两部&quot;) %&gt;%corpus() ;r1</code></pre>
<pre><code>## Corpus consisting of 2 documents.
## 储元熹细雪.txt :
## &quot; 一 “细姑娘[1]，劳驾帮个忙！” 从镜子里看到妙子从过道走进来，幸子头也不回地把自己正在擦脖子的粉扑儿递了过去，她像...&quot;
## 
## 周逸之细雪.txt :
## &quot; 1 “小妹，来帮我一下。”幸子正在往脖子上敷粉，从镜中看见妙子从走廊走到自己身后，便把手中的粉刷递给她，问道：“雪子在...&quot;</code></pre>
<pre class="r"><code>## readtext -&gt; tidy -&gt; mutate 
text_corpus_tidy &lt;-r1 %&gt;%
  tidy %&gt;% 
  mutate(textID = row_number())
text_corpus_tidy </code></pre>
<pre><code>## # A tibble: 2 × 2
##   text                                                                    textID
##   &lt;chr&gt;                                                                    &lt;int&gt;
## 1 &quot;\n一\n\n\n“细姑娘[1]，劳驾帮个忙！”\n\n从镜子里看到妙子从过道走进来，…      1
## 2 &quot;\n\n\n1\n\n\n“小妹，来帮我一下。”幸子正在往脖子上敷粉，从镜中看见妙子…      2</code></pre>
<pre class="r"><code># tokenization use jiebaR   4and more
text_tokens &lt;- text_corpus_tidy$text %&gt;%
  segment(jiebar = my_seg) %&gt;%
  as.tokens 
text_tokens</code></pre>
<pre><code>## Tokens consisting of 2 documents.
## text1 :
##  [1] &quot;\n&quot;   &quot;一&quot;   &quot;\n&quot;   &quot;\n&quot;   &quot;\n&quot;   &quot;“&quot;    &quot;细&quot;   &quot;姑娘&quot; &quot;[&quot;    &quot;1&quot;   
## [11] &quot;]&quot;    &quot;，&quot;  
## [ ... and 255,413 more ]
## 
## text2 :
##  [1] &quot;\n&quot;   &quot;\n&quot;   &quot;\n&quot;   &quot;1&quot;    &quot;\n&quot;   &quot;\n&quot;   &quot;\n&quot;   &quot;“&quot;    &quot;小妹&quot; &quot;，&quot;  
## [11] &quot;来&quot;   &quot;帮&quot;  
## [ ... and 261,178 more ]</code></pre>
</div>
<div id="remove-everything-you-dont-want-to-see" class="section level2">
<h2>5.remove everything you don’t want to see</h2>
<pre class="r"><code>toks &lt;- tokens(text_tokens, remove_punct = TRUE, remove_numbers = TRUE) %&gt;% 
  tokens_remove(pattern = stopwords(&quot;zh_cn&quot;, source = &quot;marimo&quot;), min_nchar = 4,max_nchar=4,padding=F)%&gt;% ##min_nchar = 4,max_nchar=4 四字成语,but we need further work
  tokens_select(pattern = &quot;^\\p{script=Hani}+$&quot;,valuetype = &#39;regex&#39;,verbose = quanteda_options(&quot;verbose&quot;), padding=F)</code></pre>
</div>
<div id="convert-the-dictionary-to-a-character" class="section level2">
<h2>6.convert the dictionary to a character</h2>
<pre class="r"><code>## you need to make the dictionary file to a csv file .
mywordlistcsv &lt;- read_csv(&quot;/Users/oushiei/Downloads/四字词文件/成语.csv&quot;) %&gt;% as.list()
mywordlistcsvlist &lt;- mywordlistcsv%&gt;% unlist %&gt;% as.character()</code></pre>
</div>
<div id="compare" class="section level2">
<h2>7.compare</h2>
<pre class="r"><code>##将字符串的字符与现在的所有成语进行比较
t1 &lt;- tokens_select(toks,pattern = mywordlistcsvlist, selection = &quot;keep&quot;);t1</code></pre>
<pre><code>## Tokens consisting of 2 documents.
## text1 :
##  [1] &quot;目不转睛&quot; &quot;一无所知&quot; &quot;自作主张&quot; &quot;一清二楚&quot; &quot;大家闺秀&quot; &quot;寻花问柳&quot;
##  [7] &quot;不在话下&quot; &quot;卧床不起&quot; &quot;开门见山&quot; &quot;转弯抹角&quot; &quot;口若悬河&quot; &quot;长篇大论&quot;
## [ ... and 1,737 more ]
## 
## text2 :
##  [1] &quot;自作主张&quot; &quot;戛然而止&quot; &quot;自作主张&quot; &quot;一清二楚&quot; &quot;大家闺秀&quot; &quot;过意不去&quot;
##  [7] &quot;名噪一时&quot; &quot;一误再误&quot; &quot;循规蹈矩&quot; &quot;寻花问柳&quot; &quot;精明干练&quot; &quot;花言巧语&quot;
## [ ... and 2,050 more ]</code></pre>
<pre class="r"><code>##浅看一下所有的四字格
summary(t1)</code></pre>
<pre><code>##       Length Class  Mode     
## text1 1749   -none- character
## text2 2062   -none- character</code></pre>
<pre class="r"><code>##token格式不可以直接输出为外部文件,所以继续导出为dfm
pchu &lt;- t1[1];pchu</code></pre>
<pre><code>## Tokens consisting of 1 document.
## text1 :
##  [1] &quot;目不转睛&quot; &quot;一无所知&quot; &quot;自作主张&quot; &quot;一清二楚&quot; &quot;大家闺秀&quot; &quot;寻花问柳&quot;
##  [7] &quot;不在话下&quot; &quot;卧床不起&quot; &quot;开门见山&quot; &quot;转弯抹角&quot; &quot;口若悬河&quot; &quot;长篇大论&quot;
## [ ... and 1,737 more ]</code></pre>
<pre class="r"><code>pzhou &lt;- t1[2];pzhou</code></pre>
<pre><code>## Tokens consisting of 1 document.
## text2 :
##  [1] &quot;自作主张&quot; &quot;戛然而止&quot; &quot;自作主张&quot; &quot;一清二楚&quot; &quot;大家闺秀&quot; &quot;过意不去&quot;
##  [7] &quot;名噪一时&quot; &quot;一误再误&quot; &quot;循规蹈矩&quot; &quot;寻花问柳&quot; &quot;精明干练&quot; &quot;花言巧语&quot;
## [ ... and 2,050 more ]</code></pre>
<pre class="r"><code>##继续导出为dfm
dfmat &lt;- dfm(t1)
dfmat</code></pre>
<pre><code>## Document-feature matrix of: 2 documents, 1,466 features (32.40% sparse) and 0 docvars.
##        features
## docs    目不转睛 一无所知 自作主张 一清二楚 大家闺秀 寻花问柳 不在话下 卧床不起
##   text1        4        3        9        3        6        1        1        1
##   text2        3        2        8        5        9        3        0        1
##        features
## docs    开门见山 转弯抹角
##   text1        3        3
##   text2        0        0
## [ reached max_nfeat ... 1,456 more features ]</code></pre>
<pre class="r"><code>##转换为dataf
out &lt;- convert(dfm(t1), to = &quot;data.frame&quot;)
my_df &lt;- out %&gt;% 
  pivot_longer(cols = c(!doc_id), names_to = &quot;tokens&quot;, values_to = &quot;freq&quot;)
my_df</code></pre>
<pre><code>## # A tibble: 2,932 × 3
##    doc_id tokens    freq
##    &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;
##  1 text1  目不转睛     4
##  2 text1  一无所知     3
##  3 text1  自作主张     9
##  4 text1  一清二楚     3
##  5 text1  大家闺秀     6
##  6 text1  寻花问柳     1
##  7 text1  不在话下     1
##  8 text1  卧床不起     1
##  9 text1  开门见山     3
## 10 text1  转弯抹角     3
## # … with 2,922 more rows</code></pre>
</div>
<div id="conclusion" class="section level2">
<h2>8.conclusion</h2>
<ul>
<li><p>1.jiebaR和quanteda包组合使用是可行的</p></li>
<li><p>2.利用搜狗词库的成语词典可以精准的将成语分词并提取,再结合quanteda的select功能,以一一比对抽出所有四字词,避免了人工清洁语料的过程</p></li>
<li><p>3.该词包只有4字与4字以上的成语,本研究只选取了4字,还有部分4字以上的成语未被提取,搜狗也有三字成语的词库,同理可以抽取所有三字成语.</p></li>
</ul>
</div>
